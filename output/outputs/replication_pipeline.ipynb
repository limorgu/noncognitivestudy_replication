{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b467db5f",
   "metadata": {},
   "source": [
    "\n",
    "# Non-Cognitive Interventions — Replication Pipeline (RQ1–RQ4)\n",
    "\n",
    "This notebook runs the full analysis pipeline and **saves every step** to CSV:\n",
    "- A *pre-model analysis dataset* for each RQ\n",
    "- A *results* CSV for each RQ\n",
    "\n",
    "## Inputs expected\n",
    "- `data/stud_ex.csv` — student-level summary per experiment\n",
    "- `data/dat.csv` — problem-level logs (for posttest; item-level)\n",
    "\n",
    "> If you don’t have `data/dat.csv`, export it from your R preprocessing (`dat`) or build it from the long/problem-level Python frame and write it to `data/dat.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9cade2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: /Users/limorki/Documents/Replication_Educ/noncognitivestudy_replication/output/outputs/data\n",
      "Outputs dir: /Users/limorki/Documents/Replication_Educ/noncognitivestudy_replication/output/outputs/outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_STUD_EX = DATA_DIR / \"stud_ex.csv\"\n",
    "IN_DAT     = DATA_DIR / \"dat.csv\"\n",
    "\n",
    "def safe_binary(s):\n",
    "    \"\"\"Coerce True/False/'TRUE'/'FALSE'/0/1 to float 0/1.\"\"\"\n",
    "    return pd.Series(s).replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float)\n",
    "\n",
    "def holm_adjust(pvals: pd.Series) -> pd.Series:\n",
    "    mask = pvals.notna().values\n",
    "    adj = np.full_like(pvals.astype(float).values, np.nan, dtype=float)\n",
    "    if mask.sum() > 0:\n",
    "        _, p_holm, _, _ = multipletests(pvals[mask].values, alpha=0.05, method=\"holm\")\n",
    "        adj[mask] = p_holm\n",
    "    return pd.Series(adj, index=pvals.index)\n",
    "\n",
    "print(\"Data dir:\", DATA_DIR.resolve())\n",
    "print(\"Outputs dir:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stud_ex shape: (16511, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "assignment_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "psa_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "student_class_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "teacher_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "academic_year",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_hints",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_first_response_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "skb_problem_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_sb_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_pt_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "posttest_responses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mastery",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "treatment",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "control",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "condition",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "91dcb067-f866-48b9-8f8f-f1232ff95ac6",
       "rows": [
        [
         "0",
         "14671",
         "1210679",
         "PSAV89B",
         "1180471",
         "11341",
         "v2_20_21",
         "Confidence Judgments",
         "0",
         "82228.66666666667",
         "3.0",
         "1.0",
         null,
         "0",
         "True",
         "0",
         "1",
         "control"
        ],
        [
         "1",
         "18550",
         "851142",
         "PSAV89B",
         "1929016",
         "18541",
         "v2_20_21",
         "Confidence Judgments",
         "0",
         "12789.0",
         "1.0",
         "1.0",
         null,
         "0",
         "False",
         "1",
         "0",
         "Confidence Judgments"
        ],
        [
         "2",
         "28497",
         "851140",
         "PSAV89B",
         "1929014",
         "18541",
         "v2_20_21",
         "Confidence Judgments",
         "0",
         "381119306.4",
         "5.0",
         "0.8",
         null,
         "0",
         "False",
         "0",
         "1",
         "control"
        ],
        [
         "3",
         "38595",
         "306682",
         "PSA2KQB",
         "760877",
         "707926",
         "v2_20_21",
         "Emotion Labeling",
         "0",
         "15364.25",
         "3.0",
         "1.0",
         "0.0",
         "2",
         "True",
         "0",
         "1",
         "control"
        ],
        [
         "4",
         "48886",
         "519237",
         "PSAV89B",
         "1257226",
         "46660",
         "v2_20_21",
         "Confidence Judgments",
         "25",
         "8283211.818181818",
         "11.0",
         "0.3636363636363636",
         null,
         "0",
         "False",
         "0",
         "1",
         "control"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>psa_id</th>\n",
       "      <th>student_class_id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>academic_year</th>\n",
       "      <th>experiment</th>\n",
       "      <th>num_hints</th>\n",
       "      <th>avg_first_response_time</th>\n",
       "      <th>skb_problem_count</th>\n",
       "      <th>avg_sb_accuracy</th>\n",
       "      <th>avg_pt_accuracy</th>\n",
       "      <th>posttest_responses</th>\n",
       "      <th>mastery</th>\n",
       "      <th>treatment</th>\n",
       "      <th>control</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14671</td>\n",
       "      <td>1210679</td>\n",
       "      <td>PSAV89B</td>\n",
       "      <td>1180471</td>\n",
       "      <td>11341</td>\n",
       "      <td>v2_20_21</td>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>0</td>\n",
       "      <td>8.222867e+04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18550</td>\n",
       "      <td>851142</td>\n",
       "      <td>PSAV89B</td>\n",
       "      <td>1929016</td>\n",
       "      <td>18541</td>\n",
       "      <td>v2_20_21</td>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>0</td>\n",
       "      <td>1.278900e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Confidence Judgments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28497</td>\n",
       "      <td>851140</td>\n",
       "      <td>PSAV89B</td>\n",
       "      <td>1929014</td>\n",
       "      <td>18541</td>\n",
       "      <td>v2_20_21</td>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>0</td>\n",
       "      <td>3.811193e+08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38595</td>\n",
       "      <td>306682</td>\n",
       "      <td>PSA2KQB</td>\n",
       "      <td>760877</td>\n",
       "      <td>707926</td>\n",
       "      <td>v2_20_21</td>\n",
       "      <td>Emotion Labeling</td>\n",
       "      <td>0</td>\n",
       "      <td>1.536425e+04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48886</td>\n",
       "      <td>519237</td>\n",
       "      <td>PSAV89B</td>\n",
       "      <td>1257226</td>\n",
       "      <td>46660</td>\n",
       "      <td>v2_20_21</td>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>25</td>\n",
       "      <td>8.283212e+06</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  assignment_id   psa_id  student_class_id  teacher_id  \\\n",
       "0    14671        1210679  PSAV89B           1180471       11341   \n",
       "1    18550         851142  PSAV89B           1929016       18541   \n",
       "2    28497         851140  PSAV89B           1929014       18541   \n",
       "3    38595         306682  PSA2KQB            760877      707926   \n",
       "4    48886         519237  PSAV89B           1257226       46660   \n",
       "\n",
       "  academic_year            experiment  num_hints  avg_first_response_time  \\\n",
       "0      v2_20_21  Confidence Judgments          0             8.222867e+04   \n",
       "1      v2_20_21  Confidence Judgments          0             1.278900e+04   \n",
       "2      v2_20_21  Confidence Judgments          0             3.811193e+08   \n",
       "3      v2_20_21      Emotion Labeling          0             1.536425e+04   \n",
       "4      v2_20_21  Confidence Judgments         25             8.283212e+06   \n",
       "\n",
       "   skb_problem_count  avg_sb_accuracy  avg_pt_accuracy  posttest_responses  \\\n",
       "0                3.0         1.000000              NaN                   0   \n",
       "1                1.0         1.000000              NaN                   0   \n",
       "2                5.0         0.800000              NaN                   0   \n",
       "3                3.0         1.000000              0.0                   2   \n",
       "4               11.0         0.363636              NaN                   0   \n",
       "\n",
       "   mastery  treatment  control             condition  \n",
       "0     True          0        1               control  \n",
       "1    False          1        0  Confidence Judgments  \n",
       "2    False          0        1               control  \n",
       "3     True          0        1               control  \n",
       "4    False          0        1               control  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: data/dat.csv not found. RQ4.2 will be skipped unless provided.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load inputs\n",
    "stud_ex = pd.read_csv('PATH /stud_ex__replication_ready.csv')\n",
    "print(\"stud_ex shape:\", stud_ex.shape)\n",
    "display(stud_ex.head())\n",
    "\n",
    "# dat is optional (only needed for RQ4.2). We try to load it; if missing, we warn.\n",
    "if IN_DAT.exists():\n",
    "    dat = pd.read_csv(IN_DAT)\n",
    "    print(\"dat shape:\", dat.shape)\n",
    "    display(dat.head())\n",
    "else:\n",
    "    dat = None\n",
    "    print(\"WARNING: data/dat.csv not found. RQ4.2 will be skipped unless provided.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8290960",
   "metadata": {},
   "source": [
    "## RQ1 — Response Time: `log(avg_first_response_time+1) ~ treatment` (per experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e471aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "StdErr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p_holm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sig_holm",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "0ec2d74b-6611-4b60-ab6a-375074034ee3",
       "rows": [
        [
         "0",
         "Confidence Judgments",
         "-0.0975",
         "0.0599",
         "-1.6297",
         "0.1032",
         "9316",
         "0.2064",
         "False"
        ],
        [
         "1",
         "Emotion Labeling",
         "0.057",
         "0.0413",
         "1.3792",
         "0.1679",
         "7187",
         "0.2064",
         "False"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "      <th>N</th>\n",
       "      <th>p_holm</th>\n",
       "      <th>sig_holm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>-0.0975</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>-1.6297</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>9316</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotion Labeling</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>1.3792</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>7187</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment  Estimate  StdErr       t       p     N  p_holm  \\\n",
       "0  Confidence Judgments   -0.0975  0.0599 -1.6297  0.1032  9316  0.2064   \n",
       "1      Emotion Labeling    0.0570  0.0413  1.3792  0.1679  7187  0.2064   \n",
       "\n",
       "   sig_holm  \n",
       "0     False  \n",
       "1     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rq1_rows = []\n",
    "for exp, g in stud_ex.groupby(\"experiment\"):\n",
    "    sub = g[[\"avg_first_response_time\", \"treatment\"]].dropna()\n",
    "    # Save pre-model dataset\n",
    "    ds_path = OUT_DIR / f\"rq1_dataset_{exp.replace(' ', '_')}.csv\"\n",
    "    sub.assign(experiment=exp).to_csv(ds_path, index=False)\n",
    "    if sub.empty or sub[\"treatment\"].nunique() < 2:\n",
    "        rq1_rows.append(dict(experiment=exp, Estimate=np.nan, StdErr=np.nan, t=np.nan, p=np.nan, N=len(sub)))\n",
    "        continue\n",
    "    sub = sub.copy()\n",
    "    sub[\"y\"] = np.log1p(sub[\"avg_first_response_time\"].astype(float))\n",
    "    X = add_constant(sub[\"treatment\"])\n",
    "    res = sm.OLS(sub[\"y\"], X).fit()\n",
    "    rq1_rows.append(dict(experiment=exp,\n",
    "                         Estimate=res.params[\"treatment\"],\n",
    "                         StdErr=res.bse[\"treatment\"],\n",
    "                         t=res.tvalues[\"treatment\"],\n",
    "                         p=res.pvalues[\"treatment\"],\n",
    "                         N=len(sub)))\n",
    "\n",
    "rq1 = pd.DataFrame(rq1_rows).sort_values(\"experiment\").reset_index(drop=True)\n",
    "rq1[\"p_holm\"] = holm_adjust(rq1[\"p\"])\n",
    "rq1[\"sig_holm\"] = rq1[\"p_holm\"] < 0.05\n",
    "display(rq1.round(4))\n",
    "\n",
    "# Save results\n",
    "rq1.to_csv(OUT_DIR / \"rq1_response_time_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119dc40",
   "metadata": {},
   "source": [
    "# Load PostTest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RQ4.2 RECONSTRUCTION FROM events_all__clean.csv (item-level) ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from statsmodels.genmod.bayes_mixed_glm import BinomialBayesMixedGLM\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"processed\")  # adjust if your CSV is elsewhere\n",
    "OUT_DIR  = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Load problem-level events (your \"dat\")\n",
    "events = pd.read_csv(\"ADD YOUR PATH processed/events_all__clean.csv\")\n",
    "\n",
    "# 2) Map psa_id -> experiment name and #posttest items (from the R code)\n",
    "experiments_map = {\n",
    "    \"PSA2KNM\": \"Embracing Mistakes\",\n",
    "    \"PSA2KNP\": \"Embracing Mistakes\",\n",
    "    \"PSA59TQ\": \"Inspirational Quotes\",\n",
    "    \"PSA7GUA\": \"Inspirational Quotes\",\n",
    "    \"PSA9XWV\": \"Social Comparison\",\n",
    "    \"PSA2KQB\": \"Emotion Labeling\",\n",
    "    \"PSAV89B\": \"Confidence Judgments\",\n",
    "    \"PSAWU6Z\": \"Confidence Judgments\",\n",
    "}\n",
    "posttest_n = {\n",
    "    \"PSA2KNM\": 2, \"PSA2KNP\": 2,\n",
    "    \"PSA59TQ\": 3, \"PSA7GUA\": 2,\n",
    "    \"PSA9XWV\": 3, \"PSA2KQB\": 2,\n",
    "    \"PSAV89B\": 0, \"PSAWU6Z\": 0,\n",
    "}\n",
    "\n",
    "# 3) Basic derived flags (mirrors the R)\n",
    "#    - posttest indicator\n",
    "#    - correct from continuous_score\n",
    "ev = events.copy()\n",
    "ev[\"posttest\"] = (ev[\"control_treatments\"] == \"posttest\").astype(int)\n",
    "ev[\"correct\"]  = (ev[\"continuous_score\"] == 1).astype(int)\n",
    "\n",
    "# 4) Define raw per-row control/treatment indicators (as in R)\n",
    "#    control if startswith \"control\" OR endswith \"plain_message\"\n",
    "#    treatment if startswith \"treatment\" and NOT endswith \"plain_message\"\n",
    "def _endswith_safe(s, suffix):\n",
    "    s = s.fillna(\"\")\n",
    "    return s.str.endswith(suffix)\n",
    "\n",
    "def _startswith_safe(s, prefix):\n",
    "    s = s.fillna(\"\")\n",
    "    return s.str.startswith(prefix)\n",
    "\n",
    "ct = ev[\"control_treatments\"].astype(str)\n",
    "ev[\"control_row\"]   = (_startswith_safe(ct, \"control\") | _endswith_safe(ct, \"plain_message\")).astype(int)\n",
    "ev[\"treat_row\"]     = (_startswith_safe(ct, \"treatment\") & (~_endswith_safe(ct, \"plain_message\"))).astype(int)\n",
    "ev[\"video_fail\"]    = (ct == \"video_check_fail\").astype(int)\n",
    "\n",
    "# 5) Attach experiment & #posttest per psa_id\n",
    "ev[\"experiment\"] = ev[\"psa_id\"].map(experiments_map)\n",
    "ev[\"num_posttest_problems\"] = ev[\"psa_id\"].map(posttest_n)\n",
    "\n",
    "# 6) Aggregate to assignment-level to get final treatment/control flags\n",
    "#    Grouping key matches the R logic: (user_id, psa_id, assignment_id)\n",
    "grp_keys = [\"user_id\", \"psa_id\", \"assignment_id\"]\n",
    "agg = (\n",
    "    ev.groupby(grp_keys, as_index=False)\n",
    "      .agg(\n",
    "          treat_any  = (\"treat_row\", \"sum\"),\n",
    "          control_any= (\"control_row\", \"sum\"),\n",
    "          video_fail_any=(\"video_fail\", \"sum\"),\n",
    "          posttest_responses=(\"posttest\", \"sum\"),\n",
    "          # keep the first experiment label for this assignment\n",
    "          experiment=(\"experiment\", \"first\"),\n",
    "          num_posttest_problems=(\"num_posttest_problems\",\"first\")\n",
    "      )\n",
    ")\n",
    "\n",
    "# Mark assignment-level treatment/control and \"never randomized\"\n",
    "agg[\"treatment_assign\"] = (agg[\"treat_any\"] > 0).astype(int)\n",
    "agg[\"control_assign\"]   = (agg[\"control_any\"] > 0).astype(int)\n",
    "agg[\"video_fail_any\"]   = (agg[\"video_fail_any\"] > 0).astype(int)\n",
    "agg[\"never_randomized\"] = ((agg[\"treatment_assign\"] == 0) & (agg[\"control_assign\"] == 0)).astype(int)\n",
    "\n",
    "# 7) Keep valid assignments (mirror the R filters)\n",
    "#    - drop video check fails\n",
    "#    - drop never_randomized\n",
    "valid = agg.query(\"video_fail_any == 0 and never_randomized == 0\").copy()\n",
    "\n",
    "# 8) Keep only the FIRST exposure to each psa_id per student\n",
    "#    We order by assignment_id (string order is usually stable for the IDs)\n",
    "valid[\"running_exp_count\"] = (\n",
    "    valid.sort_values(\"assignment_id\")\n",
    "         .groupby([\"user_id\", \"psa_id\"])\n",
    "         .cumcount() + 1\n",
    ")\n",
    "valid = valid.query(\"running_exp_count == 1\").copy()\n",
    "\n",
    "# 9) Merge back the assignment-level treatment into the item-level events\n",
    "ev2 = ev.merge(\n",
    "    valid[grp_keys + [\"treatment_assign\",\"experiment\",\"num_posttest_problems\",\"posttest_responses\"]],\n",
    "    on=grp_keys, how=\"inner\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec189c7",
   "metadata": {},
   "source": [
    "## RQ2 — Hint Usage: `(num_hints>0) ~ treatment` (logistic, per experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70c5d8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "StdErr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p_holm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sig_holm",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "07fbf480-5b26-42d6-a2fd-5581b509a10a",
       "rows": [
        [
         "0",
         "Confidence Judgments",
         "-0.1323",
         "0.0434",
         "-3.0451",
         "0.0023",
         "0.8761",
         "0.8046",
         "0.954",
         "9316",
         "0.0047",
         "True"
        ],
        [
         "1",
         "Emotion Labeling",
         "-0.0649",
         "0.0571",
         "-1.1367",
         "0.2557",
         "0.9371",
         "0.8378",
         "1.0482",
         "7195",
         "0.2557",
         "False"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>z</th>\n",
       "      <th>p</th>\n",
       "      <th>OR</th>\n",
       "      <th>OR_low</th>\n",
       "      <th>OR_high</th>\n",
       "      <th>N</th>\n",
       "      <th>p_holm</th>\n",
       "      <th>sig_holm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>-0.1323</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>-3.0451</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>0.8046</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>9316</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotion Labeling</td>\n",
       "      <td>-0.0649</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>-1.1367</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>1.0482</td>\n",
       "      <td>7195</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment  Estimate  StdErr       z       p      OR  OR_low  \\\n",
       "0  Confidence Judgments   -0.1323  0.0434 -3.0451  0.0023  0.8761  0.8046   \n",
       "1      Emotion Labeling   -0.0649  0.0571 -1.1367  0.2557  0.9371  0.8378   \n",
       "\n",
       "   OR_high     N  p_holm  sig_holm  \n",
       "0   0.9540  9316  0.0047      True  \n",
       "1   1.0482  7195  0.2557     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rq2_rows = []\n",
    "for exp, g in stud_ex.groupby(\"experiment\"):\n",
    "    sub = g[[\"num_hints\", \"treatment\"]].dropna().copy()\n",
    "    # Save pre-model dataset\n",
    "    ds_path = OUT_DIR / f\"rq2_dataset_{exp.replace(' ', '_')}.csv\"\n",
    "    sub.assign(experiment=exp).to_csv(ds_path, index=False)\n",
    "    if sub.empty or sub[\"treatment\"].nunique() < 2:\n",
    "        rq2_rows.append(dict(experiment=exp, Estimate=np.nan, StdErr=np.nan, z=np.nan,\n",
    "                             p=np.nan, OR=np.nan, OR_low=np.nan, OR_high=np.nan, N=len(sub)))\n",
    "        continue\n",
    "    sub[\"hint_used\"] = (sub[\"num_hints\"].astype(float) > 0).astype(float)\n",
    "    X = add_constant(sub[\"treatment\"])\n",
    "    res = sm.Logit(sub[\"hint_used\"], X).fit(disp=False)\n",
    "    b = res.params[\"treatment\"]; se = res.bse[\"treatment\"]; z = b/se\n",
    "    from scipy.stats import norm\n",
    "    p = 2*(1 - norm.cdf(abs(z)))\n",
    "    ci_l, ci_u = res.conf_int().loc[\"treatment\"].tolist()\n",
    "    rq2_rows.append(dict(experiment=exp, Estimate=b, StdErr=se, z=z, p=p,\n",
    "                         OR=np.exp(b), OR_low=np.exp(ci_l), OR_high=np.exp(ci_u), N=len(sub)))\n",
    "\n",
    "rq2 = pd.DataFrame(rq2_rows).sort_values(\"experiment\").reset_index(drop=True)\n",
    "rq2[\"p_holm\"] = holm_adjust(rq2[\"p\"])\n",
    "rq2[\"sig_holm\"] = rq2[\"p_holm\"] < 0.05\n",
    "display(rq2.round(4))\n",
    "\n",
    "# Save results\n",
    "rq2.to_csv(OUT_DIR / \"rq2_hint_usage_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872b489",
   "metadata": {},
   "source": [
    "## RQ3 — Mastery: `mastery ~ treatment` (logistic, per experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eab76b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/cjl156792_553wk_b44k9xc40000gn/T/ipykernel_77131/2205093918.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  sub[\"mastery_bin\"] = (sub[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float))\n",
      "/var/folders/cj/cjl156792_553wk_b44k9xc40000gn/T/ipykernel_77131/2205093918.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  sub[\"mastery_bin\"] = (sub[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "StdErr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR_low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p_holm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sig_holm",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "34f100ac-a77f-4d6d-b25d-4bb392b1db4e",
       "rows": [
        [
         "0",
         "Confidence Judgments",
         "-0.315",
         "0.0449",
         "-7.0199",
         "0.0",
         "0.7298",
         "0.6683",
         "0.7969",
         "9316",
         "0.0",
         "True"
        ],
        [
         "1",
         "Emotion Labeling",
         "-1.6698",
         "0.0723",
         "-23.0912",
         "0.0",
         "0.1883",
         "0.1634",
         "0.217",
         "7195",
         "0.0",
         "True"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>z</th>\n",
       "      <th>p</th>\n",
       "      <th>OR</th>\n",
       "      <th>OR_low</th>\n",
       "      <th>OR_high</th>\n",
       "      <th>N</th>\n",
       "      <th>p_holm</th>\n",
       "      <th>sig_holm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>-0.3150</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>-7.0199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.6683</td>\n",
       "      <td>0.7969</td>\n",
       "      <td>9316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotion Labeling</td>\n",
       "      <td>-1.6698</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>-23.0912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>7195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment  Estimate  StdErr        z    p      OR  OR_low  \\\n",
       "0  Confidence Judgments   -0.3150  0.0449  -7.0199  0.0  0.7298  0.6683   \n",
       "1      Emotion Labeling   -1.6698  0.0723 -23.0912  0.0  0.1883  0.1634   \n",
       "\n",
       "   OR_high     N  p_holm  sig_holm  \n",
       "0   0.7969  9316     0.0      True  \n",
       "1   0.2170  7195     0.0      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rq3_rows = []\n",
    "for exp, g in stud_ex.groupby(\"experiment\"):\n",
    "    sub = g[[\"mastery\", \"treatment\"]].dropna().copy()\n",
    "    # Save pre-model dataset\n",
    "    ds_path = OUT_DIR / f\"rq3_dataset_{exp.replace(' ', '_')}.csv\"\n",
    "    sub.assign(experiment=exp).to_csv(ds_path, index=False)\n",
    "    if sub.empty or sub[\"treatment\"].nunique() < 2:\n",
    "        rq3_rows.append(dict(experiment=exp, Estimate=np.nan, StdErr=np.nan, z=np.nan,\n",
    "                             p=np.nan, OR=np.nan, OR_low=np.nan, OR_high=np.nan, N=len(sub)))\n",
    "        continue\n",
    "    sub[\"mastery_bin\"] = (sub[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float))\n",
    "    X = add_constant(sub[\"treatment\"])\n",
    "    res = sm.Logit(sub[\"mastery_bin\"], X).fit(disp=False)\n",
    "    b = res.params[\"treatment\"]; se = res.bse[\"treatment\"]; z = b/se\n",
    "    from scipy.stats import norm\n",
    "    p = 2*(1 - norm.cdf(abs(z)))\n",
    "    ci_l, ci_u = res.conf_int().loc[\"treatment\"].tolist()\n",
    "    rq3_rows.append(dict(experiment=exp, Estimate=b, StdErr=se, z=z, p=p,\n",
    "                         OR=np.exp(b), OR_low=np.exp(ci_l), OR_high=np.exp(ci_u), N=len(sub)))\n",
    "\n",
    "rq3 = pd.DataFrame(rq3_rows).sort_values(\"experiment\").reset_index(drop=True)\n",
    "rq3[\"p_holm\"] = holm_adjust(rq3[\"p\"])\n",
    "rq3[\"sig_holm\"] = rq3[\"p_holm\"] < 0.05\n",
    "display(rq3.round(4))\n",
    "\n",
    "# Save results\n",
    "rq3.to_csv(OUT_DIR / \"rq3_mastery_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2c7c7",
   "metadata": {},
   "source": [
    "## RQ4.1 — Efficiency: `-z(skb_problem_count) ~ treatment` (OLS, mastered only, per experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56f2dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/cjl156792_553wk_b44k9xc40000gn/T/ipykernel_77131/4087619300.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_e[\"mastery_bin\"] = (df_e[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "StdErr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p_holm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sig_holm",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "4f8dd241-f6af-4f59-a246-f438cc9ec521",
       "rows": [
        [
         "0",
         "Confidence Judgments",
         "-0.2666",
         "0.0311",
         "-8.5785",
         "0.0",
         "6016",
         "0.0",
         "True"
        ],
        [
         "1",
         "Emotion Labeling",
         "0.0341",
         "0.0187",
         "1.8274",
         "0.0677",
         "5683",
         "0.0677",
         "False"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "      <th>N</th>\n",
       "      <th>p_holm</th>\n",
       "      <th>sig_holm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence Judgments</td>\n",
       "      <td>-0.2666</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>-8.5785</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotion Labeling</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>1.8274</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>5683</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment  Estimate  StdErr       t       p     N  p_holm  \\\n",
       "0  Confidence Judgments   -0.2666  0.0311 -8.5785  0.0000  6016  0.0000   \n",
       "1      Emotion Labeling    0.0341  0.0187  1.8274  0.0677  5683  0.0677   \n",
       "\n",
       "   sig_holm  \n",
       "0      True  \n",
       "1     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rq41_rows = []\n",
    "# Prepare mastered-only dataset\n",
    "df_e = stud_ex.copy()\n",
    "df_e[\"mastery_bin\"] = (df_e[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float))\n",
    "df_e = df_e[(df_e[\"mastery_bin\"] == 1) & df_e[\"skb_problem_count\"].notna()].copy()\n",
    "df_e[\"skb_problem_count\"] = df_e[\"skb_problem_count\"].astype(float)\n",
    "df_e[\"efficiency\"] = -1 * ( (df_e[\"skb_problem_count\"] - df_e[\"skb_problem_count\"].mean()) / df_e[\"skb_problem_count\"].std(ddof=0) )\n",
    "\n",
    "for exp, g in df_e.groupby(\"experiment\"):\n",
    "    sub = g[[\"efficiency\", \"treatment\"]].dropna().copy()\n",
    "    # Save pre-model dataset\n",
    "    ds_path = OUT_DIR / f\"rq41_dataset_{exp.replace(' ', '_')}.csv\"\n",
    "    sub.assign(experiment=exp).to_csv(ds_path, index=False)\n",
    "    if sub.empty or sub[\"treatment\"].nunique() < 2:\n",
    "        rq41_rows.append(dict(experiment=exp, Estimate=np.nan, StdErr=np.nan, t=np.nan, p=np.nan, N=len(sub)))\n",
    "        continue\n",
    "    X = add_constant(sub[\"treatment\"])\n",
    "    res = sm.OLS(sub[\"efficiency\"], X).fit()\n",
    "    rq41_rows.append(dict(experiment=exp,\n",
    "                          Estimate=res.params[\"treatment\"],\n",
    "                          StdErr=res.bse[\"treatment\"],\n",
    "                          t=res.tvalues[\"treatment\"],\n",
    "                          p=res.pvalues[\"treatment\"],\n",
    "                          N=len(sub)))\n",
    "\n",
    "rq41 = pd.DataFrame(rq41_rows).sort_values(\"experiment\").reset_index(drop=True)\n",
    "rq41[\"p_holm\"] = holm_adjust(rq41[\"p\"])\n",
    "rq41[\"sig_holm\"] = rq41[\"p_holm\"] < 0.05\n",
    "display(rq41.round(4))\n",
    "\n",
    "# Save results\n",
    "rq41.to_csv(OUT_DIR / \"rq41_efficiency_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c287f7b",
   "metadata": {},
   "source": [
    "## RQ4.2 — Post-test: `correct ~ treatment + (1|user_id) + (1|problem_id)` (mixed logistic, per experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62905911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data/dat.csv with 113955 rows and columns: ['user_id', 'problem_id', 'experiment', 'posttest', 'mastery', 'treatment', 'correct']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/cjl156792_553wk_b44k9xc40000gn/T/ipykernel_77131/1570334962.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  out[\"mastery\"]  = out[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# START from your long/problem-level DataFrame that has columns like:\n",
    "# ['user_id','assignment_id','psa_id','experiment','control_treatments',\n",
    "#  'posttest','mastery','problem_id','correct','section_names','first_response_time',\n",
    "#  'hint_count','continuous_score', 'control','treatment','treatment1','treatment2', ...]\n",
    "# If it's named something else (e.g., `df_long`), replace `dat_long` below.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#dat = read_csv(\"/Users/limorki/Documents/Replication_Educ/noncognitivestudy_replication/output/processed/events_all__clean.csv\")\n",
    "#stud_ex = read_csv(\"data/stud_ex__replication_ready.csv\")\n",
    "\n",
    "# Minimal schema needed for RQ4.2\n",
    "required = [\"user_id\",\"problem_id\",\"experiment\",\"posttest\",\"mastery\",\"treatment\",\"correct\"]\n",
    "\n",
    "# Use ev2, which contains the required columns (experiment_x, posttest, treatment_assign, correct)\n",
    "# Map columns to match required names\n",
    "out = ev2.rename(columns={\n",
    "    \"experiment_x\": \"experiment\",\n",
    "    \"treatment_assign\": \"treatment\"\n",
    "}).copy()\n",
    "\n",
    "missing = [c for c in required if c not in out.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"These columns are missing from your long/problem-level frame: {missing}\")\n",
    "\n",
    "# Clean up types a bit\n",
    "out[\"posttest\"] = out[\"posttest\"].astype(int)  # 1 if post-test row, else 0\n",
    "out[\"mastery\"]  = out[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(int)\n",
    "out[\"treatment\"]= pd.to_numeric(out[\"treatment\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "out[\"correct\"]  = pd.to_numeric(out[\"correct\"], errors=\"coerce\").astype(int)\n",
    "\n",
    "# (Optional) keep only columns we actually use downstream\n",
    "out = out[required]\n",
    "\n",
    "# Ensure the 'data' directory exists before writing\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Write to disk\n",
    "out.to_csv(\"data/dat.csv\", index=False)\n",
    "print(\"Wrote data/dat.csv with\", len(out), \"rows and columns:\", list(out.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e399767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Estimate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "StdErr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "OR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p_holm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sig_holm",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "cd16f7af-9caf-4d6f-b5f1-ac6dd75fc9db",
       "rows": [
        [
         "0",
         "Emotion Labeling",
         null,
         null,
         null,
         null,
         null,
         "11036",
         null,
         "False"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>z</th>\n",
       "      <th>p</th>\n",
       "      <th>OR</th>\n",
       "      <th>N</th>\n",
       "      <th>p_holm</th>\n",
       "      <th>sig_holm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emotion Labeling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         experiment  Estimate  StdErr   z   p  OR      N  p_holm  sig_holm\n",
       "0  Emotion Labeling       NaN     NaN NaN NaN NaN  11036     NaN     False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if dat is None:\n",
    "    print(\"dat.csv not available — skipping RQ4.2.\")\n",
    "else:\n",
    "    rq42_rows = []\n",
    "    # Use the 'out' DataFrame, which has the correct columns\n",
    "    dat_post = out.copy()\n",
    "    dat_post[\"mastery_bin\"] = (dat_post[\"mastery\"].replace({True:1, False:0, \"TRUE\":1, \"FALSE\":0}).astype(float))\n",
    "    dat_post = dat_post[(dat_post.get(\"posttest\", 0) == 1) & (dat_post[\"mastery_bin\"] == 1)].copy()\n",
    "\n",
    "    for exp, g in dat_post.groupby(\"experiment\"):\n",
    "        sub = g[[\"correct\", \"treatment\", \"user_id\", \"problem_id\"]].dropna().copy()\n",
    "        # Save pre-model dataset\n",
    "        ds_path = OUT_DIR / f\"rq42_dataset_{exp.replace(' ', '_')}.csv\"\n",
    "        sub.assign(experiment=exp).to_csv(ds_path, index=False)\n",
    "        if sub.empty or sub[\"treatment\"].nunique() < 2 or sub[\"correct\"].nunique() < 2:\n",
    "            rq42_rows.append(dict(experiment=exp, Estimate=np.nan, StdErr=np.nan, z=np.nan, p=np.nan, OR=np.nan, N=len(sub)))\n",
    "            continue\n",
    "        try:\n",
    "            model = BinomialBayesMixedGLM.from_formula(\n",
    "                \"correct ~ treatment\",\n",
    "                vc_formula={\"user\": \"0 + C(user_id)\", \"problem\": \"0 + C(problem_id)\"},\n",
    "                data=sub\n",
    "            )\n",
    "            fit = model.fit_vb()\n",
    "            b  = float(fit.fe_params[\"treatment\"])\n",
    "            se = float(fit.fe_sd[\"treatment\"])\n",
    "            z  = b / se\n",
    "            from scipy.stats import norm\n",
    "            p  = 2*(1 - norm.cdf(abs(z)))\n",
    "            rq42_rows.append(dict(experiment=exp, Estimate=b, StdErr=se, z=z, p=p, OR=np.exp(b), N=len(sub)))\n",
    "        except Exception as e:\n",
    "            rq42_rows.append(dict(experiment=exp, Estimate=np.nan, StdErr=np.nan, z=np.nan, p=np.nan, OR=np.nan, N=len(sub)))\n",
    "\n",
    "    rq42 = pd.DataFrame(rq42_rows).sort_values(\"experiment\").reset_index(drop=True)\n",
    "    rq42[\"p_holm\"] = holm_adjust(rq42[\"p\"])\n",
    "    rq42[\"sig_holm\"] = rq42[\"p_holm\"] < 0.05\n",
    "    display(rq42.round(4))\n",
    "\n",
    "    # Save results\n",
    "    rq42.to_csv(OUT_DIR / \"rq42_posttest_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa061914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12465d5c",
   "metadata": {},
   "source": [
    "\n",
    "### Notes\n",
    "- Each RQ cell writes two kinds of artifacts:\n",
    "  1) **`outputs/rq*_dataset_*.csv`** — the pre-model analysis dataset actually used\n",
    "  2) **`outputs/rq*_..._results.csv`** — the tidy results table\n",
    "\n",
    "- RQ4.2 requires `data/dat.csv` (item-level logs). Export `dat` from R or construct it in Python before running that cell.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
